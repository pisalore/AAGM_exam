{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align:right; font-size:14px;\"> University of Studies of Florence\n",
    "<p style=\"text-align:right; font-size:14px;\"> Department og Engineer Information </p>\n",
    "<p style=\"text-align:right; font-size:14px;\"> Pistoia, July 15, 2020 </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 align=center>Advanced Algorithm and Graph Mining Exam</h1>\n",
    "<h2 align=center>An implementation of Floyd-Warshal Algorithm and the Clustering coefficent on Italian Provinces Graph</h1>\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "__AUTHOR__ = {'lp': (\"Lorenzo Pisaneschi\",\n",
    "                    \"lorenzo.pisaneschi1@stud.unifi.it\",\n",
    "                     \"https://github.com/pisalore/AAGM_exam\")}\n",
    "\n",
    "__TOPICS__ = ['Graphs algorithms', 'Data Analysis']\n",
    "\n",
    "\n",
    "__KEYWORDS__ = ['Python', 'Jupyter', 'Graphs', 'NetworkX', 'pandas',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Introduction</h1>\n",
    "<br>\n",
    "Big Data are everywhere. For this reason we must know them and know how to read and manage them in order to obtain\n",
    "useful information for our community. This concept is stronger during such an event as a pandemic as we are living just\n",
    "now with the COVID-19 caused by the new SARS-CoV-2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Main topics</h1>\n",
    "\n",
    "In this work I present two main topic:\n",
    "<ul>\n",
    "    <li> Graphs generation and graphs' algorithms application with NetworkX\n",
    "    <li> Data analysis with Pandas\n",
    "</ul>\n",
    "\n",
    "Both of them are based on official Italian CIvil Protection COVID-19 data.\n",
    "\n",
    "In the first part, Italian provinces graphs and some random dimension graphs are build. They will be used to run two\n",
    "algorithms, the Floyd-Warshall algorithm and one which computes graphs' clustering coefficient.\n",
    "In the second part, Italian COVID-19 pandemic evolution is investigated thank to Pandas, Matplotlib and Geopandas, which\n",
    "are very powerful Python's modules for Data Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Data format</h1>\n",
    "\n",
    "Data of interest are the ones related to Italian Regions and Provinces. Both are available in JSON format and one\n",
    "completes the other: information about Provinces make Region Data analysis more exhaustive.\n",
    "\n",
    "Algorithms and performance analysis have been ran on **Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz** using Ubuntu 19.10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Example: Region JSON object</h2>\n",
    "<br>\n",
    "\n",
    "```json\n",
    "{\n",
    "        \"data\": \"2020-06-25T17:00:00\",\n",
    "        \"stato\": \"ITA\",\n",
    "        \"codice_regione\": 9,\n",
    "        \"denominazione_regione\": \"Toscana\",\n",
    "        \"lat\": 43.76923077,\n",
    "        \"long\": 11.25588885,\n",
    "        \"ricoverati_con_sintomi\": 24,\n",
    "        \"terapia_intensiva\": 6,\n",
    "        \"totale_ospedalizzati\": 30,\n",
    "        \"isolamento_domiciliare\": 294,\n",
    "        \"totale_positivi\": 324,\n",
    "        \"variazione_totale_positivi\": -6,\n",
    "        \"nuovi_positivi\": 2,\n",
    "        \"dimessi_guariti\": 8799,\n",
    "        \"deceduti\": 1101,\n",
    "        \"casi_da_sospetto_diagnostico\": 10107,\n",
    "        \"casi_da_screening\": 117,\n",
    "        \"totale_casi\": 10224,\n",
    "        \"tamponi\": 323864,\n",
    "        \"casi_testati\": 222294\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Example: Province JSON object</h2>\n",
    "<br>\n",
    "\n",
    "```json\n",
    "{\n",
    "        \"data\": \"2020-06-25T17:00:00\",\n",
    "        \"stato\": \"ITA\",\n",
    "        \"codice_regione\": 9,\n",
    "        \"denominazione_regione\": \"Toscana\",\n",
    "        \"codice_provincia\": 47,\n",
    "        \"denominazione_provincia\": \"Pistoia\",\n",
    "        \"sigla_provincia\": \"PT\",\n",
    "        \"lat\": 43.933465,\n",
    "        \"long\": 10.91734146,\n",
    "        \"totale_casi\": 743\n",
    "    }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Build the Provinces graph and random graphs</h1>\n",
    "\n",
    "In the first part, data of interest are only the provincial ones, in particular the **longitude and latitude**. This is\n",
    "because the goal is to build an **undirected weighted Italian Provinces graph** starting from these two geographic coordinates.\n",
    "Moreover, two cities are connected if, given x (longitude) and y (latitude) for city \"a\", then city \"b\" is in position\n",
    "z (longitude), w (latitude ) with z in [x-d,x+d] and w in [y-d, y+d], where d=0.8.\n",
    "\n",
    "The graph is weighted: an edge E which connects the nodes (cities) \"a\" and \"b\" has a weight which is the euclidean distance\n",
    "between the two cities.\n",
    "\n",
    "Then, in order to perform some computation analysis on Floyd-Warshall algorithm and to compute clustering coefficients, ten\n",
    "random graphs and one 2000 nodes sparser graph are build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Build weighted undirected graphs: first strategy</h2>\n",
    "\n",
    "The first graph build-up strategy is the expensive one. Its implementation is very easy: iterate over all the nodes\n",
    "computing all possible combinations and calculating all distances (weights) If the distance between two cities is less\n",
    "than 0.8, they are connected. Its complexity is $O(n^2) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def set_provinces_edges_expensive(graph, thrs):\n",
    "    for a in graph.nodes(data=True):\n",
    "        for b in graph.nodes(data=True):\n",
    "            if (a[1]['long'] - thrs < b[1]['long'] < a[1]['long'] + thrs) \\\n",
    "                and (a[1]['lat'] - thrs < b[1]['lat'] < a[1]['lat'] + thrs):\n",
    "                graph.add_edge(a[0], b[0], a=a[1]['city'], b=b[1]['city'],\n",
    "                weight=d(a[1]['long'], a[1]['lat'], b[1]['long'],b[1]['lat']))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Build weighted undirected graphs: second more efficient strategy. Idea.</h2>\n",
    "\n",
    "It is possible to do better than $O(n^2) $. It is mandatory to do better, moreover if we have to manage larger and\n",
    "larger graphs, as in this case. So, **binary search** could help us, as long as we work with **sorted lists**. In this case,\n",
    "we can store sort cities by longitude in a data structure; in another data structure, we can memorize sort cities by\n",
    "latitude. Then, for each city we store those that are close, by longitude and by latitude, in two separated lists, using\n",
    "binary search. Finally, for each city we compute the intersection between its above mentioned special lists. This\n",
    "intersection will output the near cities for each one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Build weighted undirected graphs: second more efficient strategy. Implementation and analysis.</h2>\n",
    "\n",
    "The complexity of this procedure is $O(nlogn) $, where the sort procedure dominates, but it is a good trade-off, since our\n",
    "graph node lists can be very large. So, here all the steps followed in order to generate efficiently a graph.\n",
    "\n",
    "Given a graph $ G = (V, E)$,\n",
    "1.  $ sorted_x = TimSort(V, long)$\n",
    "2.  $ sorted_y = TimSort(V, lat)$\n",
    "3.  $ for\\, each\\, city\\, compute\\, nearX\\, and \\, nearY$\n",
    "4.  $ for\\, each\\, city\\, compute\\, A = nearX \\cap nearY$\n",
    "\n",
    "Note that \"*TimSort* is an hybrid stable sorting algorithm, derived from merge sort and insertion sort, used in Python.\n",
    "The algorithm finds subsequences of the data that are already ordered (runs) and uses them to sort the remainder\n",
    "more efficiently\" from [Timsort Wikipedia](https://en.wikipedia.org/wiki/Timsort)\n",
    "\n",
    "Intersection is computed efficiently using Python **Sets**: $O(min(len(list1), len(list2))) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Random graphs</h2>\n",
    "\n",
    "Now we have correctly build a weighted graph containing all (107) italian provinces, where weights are distances between\n",
    "connected provinces.\n",
    "Obviously, other random graphs are build up with the strategy shown above.\n",
    "```python\n",
    "import networkx as nx\n",
    "import random\n",
    "def construct_random_graph(nodes_num, x_inf, x_sup, y_inf, y_sup):\n",
    "    graph = nx.Graph()\n",
    "    for node_id in range(nodes_num):\n",
    "        graph.add_node(node_id, city=str(node_id), long=random.uniform(x_inf, x_sup), lat=random.uniform(y_inf, y_sup))\n",
    "    return graph\n",
    "```\n",
    "\n",
    "Where:\n",
    "1. **nodes_num** is n\n",
    "2. **(x_inf, x_sup)** is the range for random longitude\n",
    "3. **(y_inf, y_sup)** is the range for random latitude\n",
    "\n",
    "A random graph is treated as the \"special\" provinces graph in the edge set up procedure. In this procedure, a \"threshold\"\n",
    "parameter is indicated: it is used in defining the \"closeness\" criteria between nodes/cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Experimental graph construction test</h2>\n",
    "\n",
    "This graph shows why the \"binary search strategy\" is really better then the \"expensive\" one.\n",
    "\n",
    "<img src=\"images/graph_construction_times.png\" width=\"600\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Floyd-Warshall algorithm</h1>\n",
    "\n",
    "Now it is possible to play with some algorithm, using the provinces and random graphs. The first algorithm here presented\n",
    "is the **Floyd-Warshall algorithm**. Floyd-Warshall algorithm is used for finding the shortest path between all\n",
    "the pairs of vertices in a weighted graph, with positive or negative edge weights (but without negative cycles).\n",
    "\n",
    "The Floyd–Warshall algorithm compares all possible paths through the graph between each pair of vertices.\n",
    "It is able to do this with $ O(|V|^3)$, even if there may be up to $ \\Omega(|V|^2)$ edges in the graph. Every combination is\n",
    "tested, incrementally improving an estimate on the shortest path between two vertices, until the estimate is optimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Idea. I</h2>\n",
    "\n",
    "The algorithm basis is the **dynamic programming**. It refers to simplifying a complicated problem by breaking it down into\n",
    "simpler sub-problems in a recursive manner. In the Floyd-Warshall algorithm is possible to use this technique, since\n",
    "sub-problem can be nested in recursively inside larger problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Idea. II</h2>\n",
    "\n",
    "Consider a graph $ G = (V, E)$, and a function $ shortestPath(i, j, k) $ that returns the shortest possible path from\n",
    "from $i $ to $j $ using vertices only from the set $\\left\\{ 1 , 2 ,.., k\\right\\} $ as intermediate points along the way.\n",
    "Now, given this function, our goal is to find the shortest path from each from each $i $ to $j $ using any vertex in\n",
    "the set $\\left\\{ 1 , 2 ,.., N\\right\\}. $\n",
    "The $ shortestPath(i, j, k) $ could be:\n",
    "1. a path that does not go through $\\left\\{ 1 , 2 ,.., k\\right\\} $, (uses only vertices in $\\left\\{ 1 , 2 ,.., k - 1\\right\\}) $\n",
    "2. a path that does go through $\\left\\{ 1 , 2 ,.., k\\right\\} $ (from $i $ to $k $  and\n",
    "then from from $k $ to $j $ , both only using intermediate vertices in $\\left\\{ 1 , 2 ,.., k - 1\\right\\}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Idea. III</h2>\n",
    "\n",
    "\n",
    "If $w(i,j) $ is the weight of the edge between vertices $k $ and $j $, we can define $ shortestPath(i, j, k) $\n",
    "in terms of the following recursive formula: the base case is\n",
    "* $ shortestPath(i, j, 0) = w(i,j) $\n",
    "\n",
    "and the recursive case is\n",
    "\n",
    "* $ shortestPath(i, j, k) = min(shortestPath(i, j, k-1),$\n",
    "$ shortestPath(i, k, k-1), shortestPath(k, j, k - 1)) $\n",
    "\n",
    "\n",
    "This formula is the heart of the Floyd–Warshall algorithm. The algorithm works by first computing\n",
    "$ shortestPath(i, j, k) $ for all $(i, j)$, pairs for $k = 1, 2, ..., N$ finding all the shortest paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Pseudo-code</h2>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "def floyd_warshall(graph):\n",
    "    n = graph.number_of_nodes()\n",
    "    sparse_adj = nx.adjacency_matrix(graph, nodelist=None, weight='weight')\n",
    "    shortest_paths = sparse_adj.toarray()\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j and shortest_paths[i][j] == 0:\n",
    "                shortest_paths[i][j] = INFINITY\n",
    "    # Core algorithm\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                shortest_paths[i][j] = min(shortest_paths[i][j],\n",
    "                shortest_paths[i][k] + shortest_paths[k][j])\n",
    "    print(shortest_paths, '\\n')\n",
    "    return shortest_paths\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Toy example</h2>\n",
    "\n",
    "This example is taken from:\n",
    "[Wikipedia Floyd-Warshall Algorithm](https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm)\n",
    "\n",
    "<img src=\"images/TOY_1.png\" width=\"700\" style=\"\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Floyd-Warshall algorithm. Execution times.</h2>\n",
    "<br>\n",
    "\n",
    "| Graph dimensions         | 100     | 200    | 300    | 400     | 500     | 600    | 700     | 800      | 900      | 1000     | 2000      |\n",
    "|--------------------------|---------|--------|--------|---------|---------|--------|---------|----------|----------|----------|-----------|\n",
    "| Elapsed times            | 3.0552s | 25.067s | 83.724s | 196.82s | 396.74s | 707.23s | 1107.1s | 1653.5s | 2388.5s | 3267.2s | 25878s |\n",
    "\n",
    "<img src=\"images/fw_times.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Clustering coefficient</h1>\n",
    "\n",
    "In graph theory, the **clustering coefficient** measures how much nodes tends to be connected between them.\n",
    "In real world graph, it is evident that nodes tend to form highly connected clusters, with an high number of links.\n",
    "\n",
    "There are two different clustering coefficients:\n",
    "1. **Local clustering coefficient**\n",
    "\n",
    "2. **Global clustering coefficient**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Local clustering coefficient</h2>\n",
    "\n",
    "The local clustering coefficient of a node is a metric which measures how much node's neighbours tend to form a clique.\n",
    "Given a graph $ G = (V, E)$\n",
    "\n",
    "* $e_{ij} $ is a connection between nodes $i, j \\in V$\n",
    "* $ N_i = \\left\\{v_j:\\langle e_{ij},e_{ji}\\rangle \\in E^2\\right\\} $\n",
    "* $k_i = |N_i| $\n",
    "\n",
    "Then, if the graph is oriented, the clustering coefficient if\n",
    "\n",
    "* $C_i = \\frac{\\left\\{ | e_{jk}:v_j, v_k \\in N_i e_{jk} \\in E | \\right\\}}{k_i(k_i -1)} $\n",
    "\n",
    "Else, if G is not oriented\n",
    "\n",
    "* $C_i = 2 * \\frac{\\left\\{ | e_{jk}:v_j, v_k \\in N_i e_{jk} \\in E | \\right\\}}{k_i(k_i -1)} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Global clustering coefficient</h2>\n",
    "\n",
    "The global clustering coefficient concept is based on triples. A **triple** consists in three nodes connected with two\n",
    "(open triple) or three (closed triple) links. A triple is related to a node. A **triangle** consists in three closed\n",
    "triples, one for each triangle's node.\n",
    "\n",
    "Global clustering coefficient is the closed triples to total triples (closed and open) ratio. It can be viewed also as\n",
    "the weighted average of all the local clustering coefficients for a network.\n",
    "\n",
    "$C_i = \\frac{3 * n_{\\Delta}(G)}{n_{\\wedge}(G)} = \\frac{\\sum_{i=1}^{n} (C_i * w_i)}{\\sum_{i=1}^{n} w_i}$\n",
    "\n",
    "Where:\n",
    "* $n_{\\Delta}(G) $ are the triangles in G\n",
    "* $n_{\\wedge}(G) $ are total triples in G\n",
    "* $w_i $ is the weight for node $v_i $ (number of triples where $v_i$ is *central*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Toy example (Local clustering coefficient).</h2>\n",
    "<br>\n",
    "<img src=\"images/TOY_2.1.png\" width=\"300\" style=\"\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Toy example (Global clustering coefficient).</h2>\n",
    "<br>\n",
    "<img src=\"images/TOY_2.png\" width=\"300\">\n",
    "\n",
    "| Node | Neighbours links | Weight | Triples where node is        central |\n",
    "|------|------------------|--------|--------------------------------------|\n",
    "| 1    | 1                | 1      | ⟨2,1,5⟩                              |\n",
    "| 2    | 1/3              | 3      | ⟨1,2,3⟩, ⟨1,2,5⟩, ⟨3,2,5⟩            |\n",
    "| 3    | 0                | 1      | ⟨2,3,4⟩                              |\n",
    "| 4    | 0                | 3      | ⟨3,4,5⟩, ⟨3,4,6⟩, ⟨5,4,6⟩            |\n",
    "| 5    | 1/3              | 3      | ⟨1,5,2⟩, ⟨1,5,4⟩, ⟨2,5,4⟩            |\n",
    "| 6    | 0                | 0      |              -                       |\n",
    "\n",
    "\n",
    "$C_i = \\frac{1}{3}$\n",
    "<br>\n",
    "Source: [Wikipedia Clustering Coefficient for Graphs](https://it.wikipedia.org/wiki/Coefficiente_di_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h1>Thanks for your attention!</h1>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}